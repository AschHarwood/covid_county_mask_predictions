{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting County-Level Mask Wearing\n",
    "\n",
    "This model is an initial prototype that attempts to forecast mask wearing based on the interaction of static determinants of health behaviors, such as demographic, economic, and social indiacotrs, with information exposure from news and social media. The long-term goal would be to develop a model that is responsive to a changing information environment. Specifically, can we measure how changing information in news and media influences peoples' decision to wear a mask or not at the county-level?\n",
    "\n",
    "The secondary goal of this model is to develop a methodology for integrating realtime information flows with contextual information to predict and/or forecast how different groups of people might change their attitudes, beliefs, and/or behaviors based on an evolving information ecosystem. This type of work could be useful to quickly detect any potential changes in human behavior and help, for example, public health practioners to better allocated resources, design more targeted health communication campaigns, etc. \n",
    "\n",
    "This MVP uses as its feature set numeric inputs from the CDC Social Vulnerability Index, Measure of America Youth Disconnection Index, and Apple mobility data at the county-level, combined with county-level geolocated tweets and state geotagged Covid-related news. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The target for this model is binary classification about whether more or less than 50 percent of the population for each county wear's a mask. It's derived from the New York Times July 2020 survey into mask wearing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-hub\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "\n",
    "#!pip install talos\n",
    "\n",
    "#!pip install spacy\n",
    "\n",
    "#!pip install scikeras\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in and process data\n",
    "df = pd.read_csv('/home/aschharwood/notebooks/covid/feature_target_v1_county_nyt_cdc_moa_tweets_gdelt_apple.csv')\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "#df.info(max_cols=500)\n",
    "\n",
    "mean = df._get_numeric_data().mean()\n",
    "\n",
    "#fill empty mobility data with column mean\n",
    "df.fillna(mean, inplace=True)\n",
    "\n",
    "#df.head()\n",
    "\n",
    "df['COUNTYFP'] = df['COUNTYFP'].astype('string')\n",
    "\n",
    "#df.describe()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#create binary target\n",
    "df['always_binary'] = np.where(df['ALWAYS']>.50, 1, 0)\n",
    "\n",
    "df['always_binary'].value_counts()\n",
    "df.fillna(df._get_numeric_data().mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up text data\n",
    "df['text_tokens_str'] = df['text_tokens_str'].replace(r'\\n',' ', regex=True)\n",
    "df['High'] = df['High'].replace(r'\\n',' ', regex=True)\n",
    "df['Low'] = df['Low'].replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discard unneeded mask wearing columns\n",
    "df.drop(['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS', 'FIPS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['always_binary']\n",
    "X = df.drop('always_binary', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab spacy's language model\n",
    "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and load spacy language model\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load(disable=['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help text tokenization function\n",
    "def tokenizer(text, nlp):\n",
    "\n",
    "    token_list = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop == False and token.is_punct==False and token.like_url==False:\n",
    "            if token.text != ' ':\n",
    "                token_list.append((token.lemma_).lower())\n",
    "    str_tokens = ' '.join(token_list)\n",
    "    return str_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Googles News Stacked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['always_binary']\n",
    "X = df.drop('always_binary', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.get_dummies(X[['COUNTYFP', 'ST_ABBR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, cats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['High'] = X['High'].apply(lambda x: tokenizer(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Low'] = X['Low'].apply(lambda x: tokenizer(x, nlp))\n",
    "X['text_tokens_str'] = X['text_tokens_str'].apply(lambda x: tokenizer(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3142, 220)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3142,)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X, y], axis=1).to_csv('feature_target_text_processed_1_20_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "\n",
    "X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "X2_test = X_test.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "#X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X2_train = scaler.fit_transform(X2_train)\n",
    "\n",
    "\n",
    "X2_test = scaler.transform(X2_test)\n",
    "\n",
    "#download and set word vector pretrained model\n",
    "#embedding = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "#hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "\n",
    "print('Google news model downlownded')\n",
    "\n",
    "X_News_High_train = X_train['High']\n",
    "X_News_High_test = X_test['High']\n",
    "\n",
    "X_News_Low_train = X_train['Low']\n",
    "X_News_Low_test = X_test['Low']\n",
    "\n",
    "X_tweet_train = X_train['text_tokens_str']\n",
    "X_tweet_test = X_test['text_tokens_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#numeric input\n",
    "num_input = Input(shape=(214,))\n",
    "dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "batch_out_num = tf.keras.layers.BatchNormalization()(dense_layer_1_num) \n",
    "num_output = Dense(10, activation='relu')(batch_out_num)\n",
    "\n",
    "#tweets low\n",
    "tweets = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "dense_1_tw = Dense(16, activation='relu')(hub_layer_tw)\n",
    "dense_2_tw = Dense(8, activation='relu')(dense_1_tw)\n",
    "batch_out_tweets = tf.keras.layers.BatchNormalization()(dense_2_tw) \n",
    "tw_output = Dense(4, activation='relu')(batch_out_tweets)\n",
    "#tw_output = Dropout(0.5)(dense_3_tw)\n",
    "\n",
    "#news low\n",
    "news_low = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_nl = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(news_low)\n",
    "dense_1_nl = Dense(16, activation='relu')(hub_layer_nl)\n",
    "dense_2_nl = Dense(8, activation='relu')(dense_1_nl)\n",
    "batch_out_nl = tf.keras.layers.BatchNormalization()(dense_2_nl) \n",
    "nl_output = Dense(4, activation='relu')(batch_out_nl)\n",
    "#nl_output = Dropout(0.5)(dense_3_nl)\n",
    "\n",
    "#news high\n",
    "news_high = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_news_high = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(news_high)\n",
    "dense_1_news_high = Dense(16, activation='relu')(hub_layer_news_high)\n",
    "dense_2_nh = Dense(8, activation='relu')(dense_1_news_high)\n",
    "batch_out_nh = tf.keras.layers.BatchNormalization()(dense_2_nh) \n",
    "nh_output = Dense(4, activation='relu')(batch_out_nh)\n",
    "#nh_output = Dropout(0.5)(dense_3_nh)\n",
    "\n",
    "\n",
    "#concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "concat_layer = Concatenate()([num_output, tw_output, nl_output, nh_output])\n",
    "# dense_1_cl = Dense(100, activation='relu')(concat_layer)\n",
    "# dense_2_cl = Dense(80, activation='relu')(dense_1_cl)\n",
    "# dense_3_cl = Dense(40, activation='relu')(dense_2_cl)\n",
    "# dense_4_cl = Dense(40, activation='relu')(dense_3_cl)\n",
    "output = Dense(1, activation='sigmoid')(concat_layer)\n",
    "model = Model(inputs=[num_input, tweets, news_low, news_high], outputs=output)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "\n",
    "validation_data=([X2_test, X_tweet_test, X_News_Low_test, X_News_High_test], y_test)\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=[X2_train, X_tweet_train, X_News_Low_train, X_News_High_train], y=y_train, epochs=5, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google news model downlownded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "\n",
    "X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "X2_test = X_test.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "#X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X2_train = scaler.fit_transform(X2_train)\n",
    "\n",
    "\n",
    "X2_test = scaler.transform(X2_test)\n",
    "\n",
    "#download and set word vector pretrained model\n",
    "#embedding = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "#hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "\n",
    "print('Google news model downlownded')\n",
    "\n",
    "X_News_High_train = X_train['High']\n",
    "X_News_High_test = X_test['High']\n",
    "\n",
    "X_News_Low_train = X_train['Low']\n",
    "X_News_Low_test = X_test['Low']\n",
    "\n",
    "X_tweet_train = X_train['text_tokens_str']\n",
    "X_tweet_test = X_test['text_tokens_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google news model downlownded\n",
      "Epoch 1/3\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 0.6218 - accuracy: 0.7409\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 0.5926 - accuracy: 0.8030\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 0.5829 - accuracy: 0.8301\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.5922 - accuracy: 0.7933\n",
      "accuracy: 79.33%\n",
      "Google news model downlownded\n",
      "Epoch 1/3\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 0.6193 - accuracy: 0.7501\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 36s 454ms/step - loss: 0.5893 - accuracy: 0.8078\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 36s 456ms/step - loss: 0.5907 - accuracy: 0.8102\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.6002 - accuracy: 0.7568\n",
      "accuracy: 75.68%\n",
      "Google news model downlownded\n",
      "Epoch 1/3\n",
      "79/79 [==============================] - 34s 435ms/step - loss: 0.6228 - accuracy: 0.7362\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 34s 435ms/step - loss: 0.5906 - accuracy: 0.8050\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 0.5864 - accuracy: 0.8162\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.6072 - accuracy: 0.8013\n",
      "accuracy: 80.13%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-6bf1a02fc97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mcvscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.2f%% (+/- %.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "    X2_test = X_test.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "    #X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    X2_train = scaler.fit_transform(X2_train)\n",
    "\n",
    "\n",
    "    X2_test = scaler.transform(X2_test)\n",
    "\n",
    "    #download and set word vector pretrained model\n",
    "    #embedding = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "    #hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "    embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "\n",
    "    print('Google news model downlownded')\n",
    "\n",
    "    X_News_High_train = X_train['High']\n",
    "    X_News_High_test = X_test['High']\n",
    "\n",
    "    X_News_Low_train = X_train['Low']\n",
    "    X_News_Low_test = X_test['Low']\n",
    "\n",
    "    X_tweet_train = X_train['text_tokens_str']\n",
    "    X_tweet_test = X_test['text_tokens_str']\n",
    "    \n",
    "    #numeric input\n",
    "    num_input = Input(shape=(214,))\n",
    "    dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "    batch_out_num = tf.keras.layers.BatchNormalization()(dense_layer_1_num) \n",
    "    num_output = Dense(10, activation='relu')(batch_out_num)\n",
    "\n",
    "    #tweets low\n",
    "    tweets = Input(shape=[], dtype=tf.string)\n",
    "    hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "    dense_1_tw = Dense(16, activation='relu')(hub_layer_tw)\n",
    "    dense_2_tw = Dense(8, activation='relu')(dense_1_tw)\n",
    "    batch_out_tweets = tf.keras.layers.BatchNormalization()(dense_2_tw) \n",
    "    tw_output = Dense(4, activation='relu')(batch_out_tweets)\n",
    "    #tw_output = Dropout(0.5)(dense_3_tw)\n",
    "\n",
    "    #news low\n",
    "    news_low = Input(shape=[], dtype=tf.string)\n",
    "    hub_layer_nl = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(news_low)\n",
    "    dense_1_nl = Dense(16, activation='relu')(hub_layer_nl)\n",
    "    dense_2_nl = Dense(8, activation='relu')(dense_1_nl)\n",
    "    batch_out_nl = tf.keras.layers.BatchNormalization()(dense_2_nl) \n",
    "    nl_output = Dense(4, activation='relu')(batch_out_nl)\n",
    "    #nl_output = Dropout(0.5)(dense_3_nl)\n",
    "\n",
    "    #news high\n",
    "    news_high = Input(shape=[], dtype=tf.string)\n",
    "    hub_layer_news_high = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(news_high)\n",
    "    dense_1_news_high = Dense(16, activation='relu')(hub_layer_news_high)\n",
    "    dense_2_nh = Dense(8, activation='relu')(dense_1_news_high)\n",
    "    batch_out_nh = tf.keras.layers.BatchNormalization()(dense_2_nh) \n",
    "    nh_output = Dense(4, activation='relu')(batch_out_nh)\n",
    "    #nh_output = Dropout(0.5)(dense_3_nh)\n",
    "\n",
    "\n",
    "    #concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "    concat_layer = Concatenate()([num_output, tw_output, nl_output, nh_output])\n",
    "    # dense_1_cl = Dense(100, activation='relu')(concat_layer)\n",
    "    # dense_2_cl = Dense(80, activation='relu')(dense_1_cl)\n",
    "    # dense_3_cl = Dense(40, activation='relu')(dense_2_cl)\n",
    "    # dense_4_cl = Dense(40, activation='relu')(dense_3_cl)\n",
    "    output = Dense(1, activation='sigmoid')(concat_layer)\n",
    "    model = Model(inputs=[num_input, tweets, news_low, news_high], outputs=output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(x=[X2_train, X_tweet_train, X_News_Low_train, X_News_High_train], y=y_train, epochs=3, callbacks=callbacks, verbose=1)\n",
    "    validation_data=([X2_test, X_tweet_test, X_News_Low_test, X_News_High_test], y_test)\n",
    "    scores = model.evaluate([X2_test, X_tweet_test, X_News_Low_test, X_News_High_test], y_test)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.38% (+/- 1.94%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning with Keras Tuner and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_num= scaler.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.77821685e-03, 1.78738771e-03, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [6.34264212e-03, 2.02634647e-03, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.79317429e-03, 4.07447947e-03, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.42862392e-02, 2.03347661e-03, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.53644232e-02, 7.97585497e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.64589410e-02, 6.95683898e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop'):\n",
    "    num_input = Input(shape=(214,))\n",
    "    dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "    num_output = Dense(1, activation='sigmoid')(dense_layer_1_num)\n",
    "    model = Model(inputs=[num_input], outputs=num_output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=.01),\n",
    "                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "# Create hyperparameter space\n",
    "epochs = [5, 7]\n",
    "batches = [None, 100, 500]\n",
    "#optimizers = [tf.keras.optimizers.Adam(lr=.01), tf.keras.optimizers.Adam(lr=.001)]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(epochs=epochs, batch_size=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s 776us/step - loss: 0.6828 - accuracy: 0.5692\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 739us/step - loss: 0.6295 - accuracy: 0.7397\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 725us/step - loss: 0.6033 - accuracy: 0.8152\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 734us/step - loss: 0.6009 - accuracy: 0.8114\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 760us/step - loss: 0.5965 - accuracy: 0.8252\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6023 - accuracy: 0.7309\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s 716us/step - loss: 0.6385 - accuracy: 0.6525\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 721us/step - loss: 0.5878 - accuracy: 0.7909\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 741us/step - loss: 0.5732 - accuracy: 0.8224\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 726us/step - loss: 0.5695 - accuracy: 0.8224\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 712us/step - loss: 0.5666 - accuracy: 0.8305\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6538 - accuracy: 0.7450\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s 711us/step - loss: 0.6793 - accuracy: 0.5556\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 722us/step - loss: 0.6411 - accuracy: 0.7160\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 720us/step - loss: 0.6076 - accuracy: 0.7871\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 720us/step - loss: 0.6002 - accuracy: 0.8086\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 791us/step - loss: 0.5967 - accuracy: 0.8062\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6473 - accuracy: 0.6953\n",
      "Epoch 1/7\n",
      "66/66 [==============================] - 0s 790us/step - loss: 0.6738 - accuracy: 0.6017\n",
      "Epoch 2/7\n",
      "66/66 [==============================] - 0s 715us/step - loss: 0.6278 - accuracy: 0.7588\n",
      "Epoch 3/7\n",
      "66/66 [==============================] - 0s 736us/step - loss: 0.6056 - accuracy: 0.8109\n",
      "Epoch 4/7\n",
      "66/66 [==============================] - 0s 719us/step - loss: 0.6013 - accuracy: 0.8142\n",
      "Epoch 5/7\n",
      "66/66 [==============================] - 0s 726us/step - loss: 0.5963 - accuracy: 0.8262\n",
      "Epoch 6/7\n",
      "66/66 [==============================] - 0s 741us/step - loss: 0.5948 - accuracy: 0.8233\n",
      "Epoch 7/7\n",
      "66/66 [==============================] - 0s 875us/step - loss: 0.5937 - accuracy: 0.8219\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5978 - accuracy: 0.7414\n",
      "Epoch 1/7\n",
      "66/66 [==============================] - 0s 709us/step - loss: 0.6489 - accuracy: 0.5981\n",
      "Epoch 2/7\n",
      "66/66 [==============================] - 0s 786us/step - loss: 0.5860 - accuracy: 0.7928\n",
      "Epoch 3/7\n",
      "66/66 [==============================] - 0s 715us/step - loss: 0.5707 - accuracy: 0.8253\n",
      "Epoch 4/7\n",
      "66/66 [==============================] - 0s 704us/step - loss: 0.5705 - accuracy: 0.8181\n",
      "Epoch 5/7\n",
      "66/66 [==============================] - 0s 771us/step - loss: 0.5695 - accuracy: 0.8253\n",
      "Epoch 6/7\n",
      "66/66 [==============================] - 0s 723us/step - loss: 0.5668 - accuracy: 0.8272\n",
      "Epoch 7/7\n",
      "66/66 [==============================] - 0s 884us/step - loss: 0.5661 - accuracy: 0.8267\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.6452 - accuracy: 0.7545\n",
      "Epoch 1/7\n",
      "66/66 [==============================] - 0s 851us/step - loss: 0.6509 - accuracy: 0.6644\n",
      "Epoch 2/7\n",
      "66/66 [==============================] - 0s 709us/step - loss: 0.6124 - accuracy: 0.7704\n",
      "Epoch 3/7\n",
      "66/66 [==============================] - 0s 709us/step - loss: 0.6016 - accuracy: 0.8005\n",
      "Epoch 4/7\n",
      "66/66 [==============================] - 0s 813us/step - loss: 0.5978 - accuracy: 0.8048\n",
      "Epoch 5/7\n",
      "66/66 [==============================] - 0s 705us/step - loss: 0.5950 - accuracy: 0.8134\n",
      "Epoch 6/7\n",
      "66/66 [==============================] - 0s 713us/step - loss: 0.5943 - accuracy: 0.8143\n",
      "Epoch 7/7\n",
      "66/66 [==============================] - 0s 753us/step - loss: 0.5931 - accuracy: 0.8148\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6313 - accuracy: 0.6781\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 863us/step - loss: 0.6997 - accuracy: 0.5287\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 830us/step - loss: 0.6851 - accuracy: 0.5334\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 818us/step - loss: 0.6674 - accuracy: 0.5745\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 866us/step - loss: 0.6517 - accuracy: 0.6939\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 854us/step - loss: 0.6372 - accuracy: 0.7507\n",
      "11/11 [==============================] - 0s 708us/step - loss: 0.6337 - accuracy: 0.7042\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 898us/step - loss: 0.6807 - accuracy: 0.5255\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 843us/step - loss: 0.6375 - accuracy: 0.6516\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 846us/step - loss: 0.6150 - accuracy: 0.7260\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 816us/step - loss: 0.5984 - accuracy: 0.7685\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 784us/step - loss: 0.5856 - accuracy: 0.8053\n",
      "11/11 [==============================] - 0s 692us/step - loss: 0.6698 - accuracy: 0.7593\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 878us/step - loss: 0.6881 - accuracy: 0.5356\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 830us/step - loss: 0.6512 - accuracy: 0.6687\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 958us/step - loss: 0.6267 - accuracy: 0.7341\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 782us/step - loss: 0.6129 - accuracy: 0.7761\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 792us/step - loss: 0.6038 - accuracy: 0.7976\n",
      "11/11 [==============================] - 0s 666us/step - loss: 0.6313 - accuracy: 0.6552\n",
      "Epoch 1/7\n",
      "21/21 [==============================] - 0s 891us/step - loss: 0.6864 - accuracy: 0.5564\n",
      "Epoch 2/7\n",
      "21/21 [==============================] - 0s 827us/step - loss: 0.6562 - accuracy: 0.6590\n",
      "Epoch 3/7\n",
      "21/21 [==============================] - 0s 824us/step - loss: 0.6367 - accuracy: 0.7192\n",
      "Epoch 4/7\n",
      "21/21 [==============================] - 0s 900us/step - loss: 0.6198 - accuracy: 0.7822\n",
      "Epoch 5/7\n",
      "21/21 [==============================] - 0s 873us/step - loss: 0.6092 - accuracy: 0.8032\n",
      "Epoch 6/7\n",
      "21/21 [==============================] - 0s 802us/step - loss: 0.6024 - accuracy: 0.8190\n",
      "Epoch 7/7\n",
      "21/21 [==============================] - 0s 923us/step - loss: 0.5978 - accuracy: 0.8266\n",
      "11/11 [==============================] - 0s 718us/step - loss: 0.6033 - accuracy: 0.7519\n",
      "Epoch 1/7\n",
      "21/21 [==============================] - 0s 913us/step - loss: 0.6725 - accuracy: 0.5747\n",
      "Epoch 2/7\n",
      "21/21 [==============================] - 0s 865us/step - loss: 0.6247 - accuracy: 0.6802\n",
      "Epoch 3/7\n",
      "21/21 [==============================] - 0s 793us/step - loss: 0.6032 - accuracy: 0.7642\n",
      "Epoch 4/7\n",
      "21/21 [==============================] - 0s 846us/step - loss: 0.5882 - accuracy: 0.7895\n",
      "Epoch 5/7\n",
      "21/21 [==============================] - 0s 785us/step - loss: 0.5775 - accuracy: 0.8253\n",
      "Epoch 6/7\n",
      "21/21 [==============================] - 0s 884us/step - loss: 0.5721 - accuracy: 0.8277\n",
      "Epoch 7/7\n",
      "21/21 [==============================] - 0s 871us/step - loss: 0.5705 - accuracy: 0.8286\n",
      "11/11 [==============================] - 0s 659us/step - loss: 0.6636 - accuracy: 0.7564\n",
      "Epoch 1/7\n",
      "21/21 [==============================] - 0s 923us/step - loss: 0.6828 - accuracy: 0.5566\n",
      "Epoch 2/7\n",
      "21/21 [==============================] - 0s 808us/step - loss: 0.6403 - accuracy: 0.7050\n",
      "Epoch 3/7\n",
      "21/21 [==============================] - 0s 808us/step - loss: 0.6211 - accuracy: 0.7484\n",
      "Epoch 4/7\n",
      "21/21 [==============================] - 0s 794us/step - loss: 0.6095 - accuracy: 0.7900\n",
      "Epoch 5/7\n",
      "21/21 [==============================] - 0s 802us/step - loss: 0.6031 - accuracy: 0.8057\n",
      "Epoch 6/7\n",
      "21/21 [==============================] - 0s 782us/step - loss: 0.6008 - accuracy: 0.8010\n",
      "Epoch 7/7\n",
      "21/21 [==============================] - 0s 795us/step - loss: 0.5987 - accuracy: 0.8062\n",
      "11/11 [==============================] - 0s 790us/step - loss: 0.6317 - accuracy: 0.6571\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.5325\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5334\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5334\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5339\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5358\n",
      "3/3 [==============================] - 0s 897us/step - loss: 0.6666 - accuracy: 0.4800\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.4702\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.4983\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6578\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.6363\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.7131\n",
      "3/3 [==============================] - 0s 852us/step - loss: 0.6758 - accuracy: 0.7230\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.5255\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5365\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6511\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6735\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6692\n",
      "3/3 [==============================] - 0s 993us/step - loss: 0.6524 - accuracy: 0.5989\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.5334\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5353\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.6046\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6356\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6476\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6920\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6958\n",
      "3/3 [==============================] - 0s 900us/step - loss: 0.6243 - accuracy: 0.6813\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.4788\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.5504\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6902\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6477\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.7394\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6117 - accuracy: 0.7060\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.7599\n",
      "3/3 [==============================] - 0s 885us/step - loss: 0.6895 - accuracy: 0.7421\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5260\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5551\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6864\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6874\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.7217\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.7360\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.7575\n",
      "3/3 [==============================] - 0s 873us/step - loss: 0.6425 - accuracy: 0.6199\n",
      "Epoch 1/7\n",
      "99/99 [==============================] - 0s 766us/step - loss: 0.6519 - accuracy: 0.6416\n",
      "Epoch 2/7\n",
      "99/99 [==============================] - 0s 743us/step - loss: 0.6099 - accuracy: 0.7715\n",
      "Epoch 3/7\n",
      "99/99 [==============================] - 0s 745us/step - loss: 0.5948 - accuracy: 0.8033\n",
      "Epoch 4/7\n",
      "99/99 [==============================] - 0s 749us/step - loss: 0.5886 - accuracy: 0.8164\n",
      "Epoch 5/7\n",
      "99/99 [==============================] - 0s 870us/step - loss: 0.5865 - accuracy: 0.8189\n",
      "Epoch 6/7\n",
      "99/99 [==============================] - 0s 767us/step - loss: 0.5839 - accuracy: 0.8272\n",
      "Epoch 7/7\n",
      "99/99 [==============================] - 0s 877us/step - loss: 0.5843 - accuracy: 0.8246\n"
     ]
    }
   ],
   "source": [
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, cv=3, param_grid=hyperparameters)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': None, 'epochs': 7}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Num Only\n",
    "\n",
    "- this model performs reasonably well with just the static socioeconomic and demographic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/15\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6287 - val_loss: 0.6687 - val_accuracy: 0.6932\n",
      "Epoch 2/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.7573 - val_loss: 0.6822 - val_accuracy: 0.7504\n",
      "Epoch 3/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.8022 - val_loss: 0.6567 - val_accuracy: 0.7313\n",
      "Epoch 4/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.8106 - val_loss: 0.6655 - val_accuracy: 0.7536\n",
      "Epoch 5/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.8066 - val_loss: 0.6584 - val_accuracy: 0.7361\n",
      "Epoch 6/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.8142 - val_loss: 0.6980 - val_accuracy: 0.7170\n",
      "Epoch 7/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.8142 - val_loss: 0.6588 - val_accuracy: 0.7345\n",
      "Epoch 8/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.8177 - val_loss: 0.6725 - val_accuracy: 0.7329\n",
      "Epoch 9/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.8166 - val_loss: 0.6902 - val_accuracy: 0.7234\n",
      "Epoch 10/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.8078 - val_loss: 0.6897 - val_accuracy: 0.7202\n",
      "Epoch 11/15\n",
      "79/79 [==============================] - 0s 988us/step - loss: 0.5757 - accuracy: 0.8193 - val_loss: 0.6636 - val_accuracy: 0.7488\n",
      "Epoch 12/15\n",
      "79/79 [==============================] - 0s 990us/step - loss: 0.5749 - accuracy: 0.8225 - val_loss: 0.6689 - val_accuracy: 0.7297\n",
      "Epoch 13/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.8237 - val_loss: 0.6897 - val_accuracy: 0.7059\n",
      "Epoch 14/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.8181 - val_loss: 0.6767 - val_accuracy: 0.7297\n",
      "Epoch 15/15\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.8201 - val_loss: 0.6568 - val_accuracy: 0.7504\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "num_input = Input(shape=(214,))\n",
    "dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "num_output = Dense(1, activation='sigmoid')(dense_layer_1_num)\n",
    "model = Model(inputs=[num_input], outputs=num_output)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "validation_data=([X2_test], y_test)\n",
    "x=[X2_train]\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=X_num, y=y, epochs=15, verbose=1, validation_split=0.2)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 214)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2150      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Debug - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd254682d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd254682d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd254687440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd254687440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 15s 196ms/step - loss: 0.6692 - accuracy: 0.6403 - val_loss: 0.6575 - val_accuracy: 0.6455\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 0.6380 - accuracy: 0.6836 - val_loss: 0.6532 - val_accuracy: 0.6455\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 0.6268 - accuracy: 0.6976 - val_loss: 0.6560 - val_accuracy: 0.6216\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 15s 196ms/step - loss: 0.6225 - accuracy: 0.7027 - val_loss: 0.6559 - val_accuracy: 0.6375\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 0.6201 - accuracy: 0.7083 - val_loss: 0.6590 - val_accuracy: 0.6264\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 0.6178 - accuracy: 0.7131 - val_loss: 0.6575 - val_accuracy: 0.6312\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 0.6171 - accuracy: 0.7139 - val_loss: 0.6578 - val_accuracy: 0.6328\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 15s 196ms/step - loss: 0.6165 - accuracy: 0.7155 - val_loss: 0.6589 - val_accuracy: 0.6264\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 15s 195ms/step - loss: 0.6160 - accuracy: 0.7163 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 15s 196ms/step - loss: 0.6160 - accuracy: 0.7163 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "tweets = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "dense_1_tw = Dense(16, activation='relu')(hub_layer_tw)\n",
    "dense_2_tw = Dense(8, activation='relu')(dense_1_tw)\n",
    "tw_output = Dense(1, activation='sigmoid')(dense_2_tw)\n",
    "\n",
    "model = Model(inputs=[tweets], outputs=tw_output)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "validation_data=([X_tweet_test], y_test)\n",
    "x=[X_tweet_train]\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=x, y=y_train, epochs=10, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model debug - stacke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd2550ca680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd2550ca680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd2550cad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd2550cad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 16s 202ms/step - loss: 0.6497 - accuracy: 0.6486 - val_loss: 0.6471 - val_accuracy: 0.6455\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 16s 199ms/step - loss: 0.6079 - accuracy: 0.7632 - val_loss: 0.6076 - val_accuracy: 0.7568\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 16s 200ms/step - loss: 0.5830 - accuracy: 0.8253 - val_loss: 0.6543 - val_accuracy: 0.6057\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 16s 199ms/step - loss: 0.5771 - accuracy: 0.8333 - val_loss: 0.6339 - val_accuracy: 0.6725\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 16s 199ms/step - loss: 0.5742 - accuracy: 0.8472 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "\n",
    "\n",
    "#numeric input\n",
    "num_input = Input(shape=(214,))\n",
    "dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "batch_out_num = tf.keras.layers.BatchNormalization()(dense_layer_1_num) \n",
    "num_output = Dense(10, activation='relu')(batch_out_num)\n",
    "\n",
    "#tweets low\n",
    "tweets = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "dense_1_tw = Dense(100, activation='relu')(hub_layer_tw)\n",
    "batch_out_tw = tf.keras.layers.BatchNormalization()(dense_1_tw) \n",
    "tw_output = Dense(32, activation='relu')(batch_out_tw)\n",
    "#tw_output = Dropout(0.5)(dense_3_tw)\n",
    "\n",
    "\n",
    "#concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "concat_layer = Concatenate()([num_output, tw_output])\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(concat_layer)\n",
    "model = Model(inputs=[num_input, tweets], outputs=output)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "validation_data=([X2_test, X_tweet_test], y_test)\n",
    "x=[X2_train, X_tweet_train]\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=x, y=y_train, epochs=5, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inital preprocessing for text using GloVe. Discarded in favor of a covid-pretrained dataset\n",
    "def preprocess_text(sen):\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "\n",
    "X1_train = []\n",
    "sentences = list(X_train['text_tokens_str'])\n",
    "for sen in sentences:\n",
    "    X1_train.append(preprocess_text(sen))\n",
    "    \n",
    "X1_test = []\n",
    "sentences = list(X_test[\"text_tokens_str\"])\n",
    "for sen in sentences:\n",
    "    X1_test.append(preprocess_text(sen))\n",
    "    \n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X1_train)\n",
    "\n",
    "X1_train = tokenizer.texts_to_sequences(X1_train)\n",
    "X1_test = tokenizer.texts_to_sequences(X1_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "X1_train = pad_sequences(X1_train, padding='post', maxlen=maxlen)\n",
    "X1_test = pad_sequences(X1_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('/home/aschharwood/notebooks/covid/notebooks/glove_tweets/glove.twitter.27B.100d.txt')\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "X2_test = X_test.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "#X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X2_train = scaler.fit_transform(X2_train)\n",
    "\n",
    "\n",
    "X2_test = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_input = Input(shape=(maxlen,))\n",
    "num_input = Input(shape=(163,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text model\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(tweet_input)\n",
    "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
    "\n",
    "#num model\n",
    "dense_layer_1 = Dense(10, activation='relu')(num_input)\n",
    "dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "concat_layer = Concatenate()([LSTM_Layer_1, dense_layer_2])\n",
    "dense_layer_3 = Dense(10, activation='relu')(concat_layer)\n",
    "output = Dense(1, activation='sigmoid')(dense_layer_3)\n",
    "model = Model(inputs=[tweet_input, num_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163) for input Tensor(\"input_26:0\", shape=(None, 163), dtype=float64), but it was called on an input with incompatible shape (None, 214).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 163) for input Tensor(\"input_26:0\", shape=(None, 163), dtype=float64), but it was called on an input with incompatible shape (None, 214).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_76 is incompatible with the layer: expected axis -1 of input shape to have value 163 but received input with shape [None, 214]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-6523ffc48ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model training complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /anaconda/envs/covid_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_76 is incompatible with the layer: expected axis -1 of input shape to have value 163 but received input with shape [None, 214]\n"
     ]
    }
   ],
   "source": [
    "print('training model')\n",
    "history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=3, verbose=1, validation_data=([X1_test, X2_test], y_test))\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_env",
   "language": "python",
   "name": "conda-env-covid_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
