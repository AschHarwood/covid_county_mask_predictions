{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /anaconda/envs/covid_env/lib/python3.7/site-packages (2.3.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (50.3.0.post20201103)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /anaconda/envs/covid_env/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in /anaconda/envs/covid_env/lib/python3.7/site-packages (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from tensorflow-hub) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from tensorflow-hub) (1.18.5)\n",
      "Requirement already satisfied: six>=1.9 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/covid_env/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow-hub) (50.3.0.post20201103)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub\n",
    "import tensorflow_hub as hub\n",
    "import datetime, os\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "pd.set_option('max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in and process data\n",
    "df = pd.read_csv('/home/aschharwood/notebooks/covid/feature_target_v1_county_nyt_cdc_moa_tweets_gdelt_apple.csv')\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "#df.info(max_cols=500)\n",
    "\n",
    "mean = df._get_numeric_data().mean()\n",
    "\n",
    "#fill empty mobility data with column mean\n",
    "df.fillna(mean, inplace=True)\n",
    "\n",
    "#df.head()\n",
    "\n",
    "df['COUNTYFP'] = df['COUNTYFP'].astype('string')\n",
    "\n",
    "#df.describe()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#create binary target\n",
    "df['always_binary'] = np.where(df['ALWAYS']>.50, 1, 0)\n",
    "\n",
    "df['always_binary'].value_counts()\n",
    "df.fillna(df._get_numeric_data().mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up text data\n",
    "df['text_tokens_str'] = df['text_tokens_str'].replace(r'\\n',' ', regex=True)\n",
    "df['High'] = df['High'].replace(r'\\n',' ', regex=True)\n",
    "df['Low'] = df['Low'].replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discard unneeded mask wearing columns\n",
    "df.drop(['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS', 'FIPS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['always_binary']\n",
    "X = df.drop('always_binary', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz in /anaconda/envs/covid_env/lib/python3.7/site-packages\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from en-core-web-sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.50.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (50.3.0.post20201103)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /anaconda/envs/covid_env/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/covid_env/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.4.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047106 sha256=d7b266569a50e657948703fd76cee73fa30e23c65fa82975b5fa705357acd886\n",
      "  Stored in directory: /home/aschharwood/.cache/pip/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
      "Successfully built en-core-web-sm\n"
     ]
    }
   ],
   "source": [
    "#grab spacy's language model\n",
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and load spacy language model\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load(disable=['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help text tokenization function\n",
    "def tokenizer(text, nlp):\n",
    "\n",
    "    token_list = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop == False and token.is_punct==False and token.like_url==False:\n",
    "            if token.text != ' ':\n",
    "                token_list.append((token.lemma_).lower())\n",
    "    str_tokens = ' '.join(token_list)\n",
    "    return str_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Googles News Stacked\n",
    "\n",
    "- This model combines numeric inputs from CDC Social Vulnerability Index, Measure of America Youth Disconnection Index, and Apple mobility data at the county-level, with county-level geolocated tweets and state geotagged Covid data. It doesn't work very at the moment, but when I run each part of the model independently, I'm starting to see results. So I have still have some debugging to do. Nevertheless, this represents an initial attempt at building a stacked neural network architecutre that combines text data with word embeddings and numeric metadata.\n",
    "\n",
    "- The target for this model is binary classification about whether more or less than 50 percent of the population for each county wear's a mask. It's derived from the New York Times July 2020 survey into mask wearing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['always_binary']\n",
    "X = df.drop('always_binary', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.get_dummies(X[['COUNTYFP', 'ST_ABBR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, cats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "X2_test = X_test.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "#X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X2_train = scaler.fit_transform(X2_train)\n",
    "\n",
    "\n",
    "X2_test = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google news model downlownded\n"
     ]
    }
   ],
   "source": [
    "#download and set word vector pretrained model\n",
    "#embedding = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "#hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "\n",
    "print('Google news model downlownded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_News_High_train = X_train['High'].apply(lambda x: tokenizer(x, nlp))\n",
    "X_News_High_test = X_test['High'].apply(lambda x: tokenizer(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_News_Low_train = X_train['Low'].apply(lambda x: tokenizer(x, nlp))\n",
    "X_News_Low_test = X_test['Low'].apply(lambda x: tokenizer(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tweet_train = X_train['text_tokens_str'].apply(lambda x: tokenizer(x, nlp))\n",
    "X_tweet_test = X_test['text_tokens_str'].apply(lambda x: tokenizer(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2513, 214)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcd69e6e250>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac4a14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac4a14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac505320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac505320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_26 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_26 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69dc0290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69dc0290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69dc0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69dc0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69d1e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69d1e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69d1e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcd69d1e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_32 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_32 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#numeric input\n",
    "num_input = Input(shape=(214,))\n",
    "dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "batch_out_num = tf.keras.layers.BatchNormalization()(dense_layer_1_num) \n",
    "num_output = Dense(10, activation='relu')(batch_out_num)\n",
    "\n",
    "#tweets low\n",
    "tweets = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "dense_1_tw = Dense(16, activation='relu')(hub_layer_tw)\n",
    "dense_2_tw = Dense(8, activation='relu')(dense_1_tw)\n",
    "batch_out_tweets = tf.keras.layers.BatchNormalization()(dense_2_tw) \n",
    "tw_output = Dense(4, activation='relu')(batch_out_tweets)\n",
    "#tw_output = Dropout(0.5)(dense_3_tw)\n",
    "\n",
    "#news low\n",
    "news_low = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_nl = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(news_low)\n",
    "dense_1_nl = Dense(16, activation='relu')(hub_layer_nl)\n",
    "dense_2_nl = Dense(8, activation='relu')(dense_1_nl)\n",
    "batch_out_nl = tf.keras.layers.BatchNormalization()(dense_2_nl) \n",
    "nl_output = Dense(4, activation='relu')(batch_out_nl)\n",
    "#nl_output = Dropout(0.5)(dense_3_nl)\n",
    "\n",
    "#news high\n",
    "news_high = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_news_high = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(news_high)\n",
    "dense_1_news_high = Dense(16, activation='relu')(hub_layer_news_high)\n",
    "dense_2_nh = Dense(8, activation='relu')(dense_1_news_high)\n",
    "batch_out_nh = tf.keras.layers.BatchNormalization()(dense_2_nh) \n",
    "nh_output = Dense(4, activation='relu')(batch_out_nh)\n",
    "#nh_output = Dropout(0.5)(dense_3_nh)\n",
    "\n",
    "\n",
    "#concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "concat_layer = Concatenate()([num_output, tw_output, nl_output, nh_output])\n",
    "dense_1_cl = Dense(100, activation='relu')(concat_layer)\n",
    "dense_2_cl = Dense(80, activation='relu')(dense_1_cl)\n",
    "dense_3_cl = Dense(40, activation='relu')(dense_2_cl)\n",
    "dense_4_cl = Dense(40, activation='relu')(dense_3_cl)\n",
    "output = Dense(1, activation='softmax')(dense_4_cl)\n",
    "model = Model(inputs=[num_input, tweets, news_low, news_high], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 34s 434ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 35s 437ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 34s 436ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 35s 440ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "validation_data=([X2_test, X_tweet_test, X_News_Low_test, X_News_High_test], y_test)\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=[X2_train, X_tweet_train, X_News_Low_train, X_News_High_train], y=y_train, epochs=5, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Num Only\n",
    "\n",
    "- this model performs reasonably well with just the static socioeconomic and demographic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/10\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7060 - val_loss: 0.5720 - val_accuracy: 0.7905\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 0s 938us/step - loss: 0.5459 - accuracy: 0.8051 - val_loss: 0.5537 - val_accuracy: 0.7905\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 0s 905us/step - loss: 0.5356 - accuracy: 0.8097 - val_loss: 0.5767 - val_accuracy: 0.7905\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 0s 963us/step - loss: 0.5393 - accuracy: 0.8062 - val_loss: 0.5984 - val_accuracy: 0.7968\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.5263 - accuracy: 0.8168 - val_loss: 0.5425 - val_accuracy: 0.8063\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.8146 - val_loss: 0.5441 - val_accuracy: 0.7714\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 0s 939us/step - loss: 0.5292 - accuracy: 0.8065 - val_loss: 0.5357 - val_accuracy: 0.8095\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8104 - val_loss: 0.5599 - val_accuracy: 0.7302\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 0s 897us/step - loss: 0.5205 - accuracy: 0.8210 - val_loss: 0.5458 - val_accuracy: 0.7587\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.5194 - accuracy: 0.8210 - val_loss: 0.5406 - val_accuracy: 0.7968\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "num_input = Input(shape=(214,))\n",
    "dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "num_output = Dense(1, activation='relu')(dense_layer_1_num)\n",
    "model = Model(inputs=[num_input], outputs=num_output)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "validation_data=([X2_test], y_test)\n",
    "x=[X2_train]\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=x, y=y_train, epochs=10, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 214)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2150      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Debug - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac594b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac594b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac597200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac597200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 16s 203ms/step - loss: 0.6410 - accuracy: 0.6407 - val_loss: 0.6543 - val_accuracy: 0.6312\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.5882 - accuracy: 0.6888 - val_loss: 0.7667 - val_accuracy: 0.6184\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.5604 - accuracy: 0.7079 - val_loss: 0.8077 - val_accuracy: 0.5978\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.5507 - accuracy: 0.7163 - val_loss: 0.8892 - val_accuracy: 0.6025\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 16s 202ms/step - loss: 0.5479 - accuracy: 0.7191 - val_loss: 0.9460 - val_accuracy: 0.6010\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.5468 - accuracy: 0.7199 - val_loss: 1.0792 - val_accuracy: 0.6200\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 16s 203ms/step - loss: 0.5465 - accuracy: 0.7203 - val_loss: 1.1376 - val_accuracy: 0.6200\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.5464 - accuracy: 0.7203 - val_loss: 1.1768 - val_accuracy: 0.6200\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 16s 202ms/step - loss: 0.5464 - accuracy: 0.7203 - val_loss: 1.1038 - val_accuracy: 0.6169\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.5464 - accuracy: 0.7203 - val_loss: 1.1752 - val_accuracy: 0.6216\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "tweets = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "dense_1_tw = Dense(16, activation='relu')(hub_layer_tw)\n",
    "dense_2_tw = Dense(8, activation='relu')(dense_1_tw)\n",
    "tw_output = Dense(1, activation='relu')(dense_2_tw)\n",
    "\n",
    "model = Model(inputs=[tweets], outputs=tw_output)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "validation_data=([X_tweet_test], y_test)\n",
    "x=[X_tweet_train]\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=x, y=y_train, epochs=10, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model debug - stacke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac292710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac292710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac292dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcdac292dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined and compiled\n",
      "training model\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 16s 202ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 16s 200ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 16s 200ms/step - loss: 0.8218 - accuracy: 0.4914 - val_loss: 0.8220 - val_accuracy: 0.4913\n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "embedding = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'\n",
    "\n",
    "\n",
    "#numeric input\n",
    "num_input = Input(shape=(214,))\n",
    "dense_layer_1_num = Dense(10, activation='relu')(num_input)\n",
    "num_output = Dense(10, activation='relu')(dense_layer_1_num)\n",
    "\n",
    "#tweets low\n",
    "tweets = Input(shape=[], dtype=tf.string)\n",
    "hub_layer_tw = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)(tweets)\n",
    "dense_1_tw = Dense(100, activation='relu')(hub_layer_tw)\n",
    "tw_output = Dense(32, activation='relu')(dense_1_tw)\n",
    "#tw_output = Dropout(0.5)(dense_3_tw)\n",
    "\n",
    "\n",
    "#concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "concat_layer = Concatenate()([num_output, tw_output])\n",
    "\n",
    "output = Dense(1, activation='softmax')(concat_layer)\n",
    "model = Model(inputs=[num_input, tweets], outputs=output)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=.1)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print('model defined and compiled')\n",
    "\n",
    "\n",
    "validation_data=([X2_test, X_tweet_test], y_test)\n",
    "x=[X2_train, X_tweet_train]\n",
    "\n",
    "print('training model')\n",
    "history = model.fit(x=x, y=y_train, epochs=5, verbose=1, validation_data=validation_data)\n",
    "print('model training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inital preprocessing for text using GloVe. Discarded in favor of a covid-pretrained dataset\n",
    "# def preprocess_text(sen):\n",
    "\n",
    "#     # Remove punctuations and numbers\n",
    "#     sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "#     # Single character removal\n",
    "#     sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "#     # Removing multiple spaces\n",
    "#     sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "#     return sentence\n",
    "\n",
    "\n",
    "\n",
    "# X1_train = []\n",
    "# sentences = list(X_train['text_tokens_str'])\n",
    "# for sen in sentences:\n",
    "#     X1_train.append(preprocess_text(sen))\n",
    "    \n",
    "# X1_test = []\n",
    "# sentences = list(X_test[\"text_tokens_str\"])\n",
    "# for sen in sentences:\n",
    "#     X1_test.append(preprocess_text(sen))\n",
    "    \n",
    "# tokenizer = Tokenizer(num_words=5000)\n",
    "# tokenizer.fit_on_texts(X1_train)\n",
    "\n",
    "# X1_train = tokenizer.texts_to_sequences(X1_train)\n",
    "# X1_test = tokenizer.texts_to_sequences(X1_test)\n",
    "\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# maxlen = 200\n",
    "\n",
    "# X1_train = pad_sequences(X1_train, padding='post', maxlen=maxlen)\n",
    "# X1_test = pad_sequences(X1_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# from numpy import array\n",
    "# from numpy import asarray\n",
    "# from numpy import zeros\n",
    "\n",
    "# embeddings_dictionary = dict()\n",
    "\n",
    "# glove_file = open('/home/aschharwood/notebooks/covid/notebooks/glove_tweets/glove.twitter.27B.100d.txt')\n",
    "\n",
    "# for line in glove_file:\n",
    "#     records = line.split()\n",
    "#     word = records[0]\n",
    "#     vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "#     embeddings_dictionary[word] = vector_dimensions\n",
    "# glove_file.close()\n",
    "\n",
    "# embedding_matrix = zeros((vocab_size, 100))\n",
    "# for word, index in tokenizer.word_index.items():\n",
    "#     embedding_vector = embeddings_dictionary.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "# X2_test = X_test.drop(['COUNTYFP', 'ST_ABBR', 'text_tokens_str', 'High', 'Low'], axis=1)\n",
    "\n",
    "# #X2_train = X_train.drop(['COUNTYFP', 'ST_ABBR'], axis=1)\n",
    "# scaler = MinMaxScaler()\n",
    "# X2_train = scaler.fit_transform(X2_train)\n",
    "\n",
    "\n",
    "# X2_test = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_input = Input(shape=(maxlen,))\n",
    "# num_input = Input(shape=(163,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #text model\n",
    "# embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(tweet_input)\n",
    "# LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
    "\n",
    "# #num model\n",
    "# dense_layer_1 = Dense(10, activation='relu')(num_input)\n",
    "# dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #concat layer takes output layers from tweet and num models, which can be passed to other models\n",
    "# concat_layer = Concatenate()([LSTM_Layer_1, dense_layer_2])\n",
    "# dense_layer_3 = Dense(10, activation='relu')(concat_layer)\n",
    "# output = Dense(1, activation='softmax')(dense_layer_3)\n",
    "# model = Model(inputs=[tweet_input, num_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "# print('model defined and compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('training model')\n",
    "# history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=3, verbose=1, validation_data=([X1_test, X2_test], y_test))\n",
    "# print('model training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_env",
   "language": "python",
   "name": "conda-env-covid_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
